{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a5889a-a5fa-415c-86c3-d0ed6df87cb6",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This notebook aims to generate and download a climate dataset from NASA, specifically focusing on data for Brazil from 2007 to 2025. The dataset will include several key variables (columns), including:\n",
    "\n",
    "- **T2M**: Temperature at 2 meters above the surface\n",
    "- **QV2M**: Humidity at 2 meters above the surface\n",
    "- **PS**: Surface pressure\n",
    "- **SWGDN**: Solar radiation\n",
    "- **PRECTOT**: Total precipitation at the surface\n",
    "\n",
    "These climate data will be sourced from the following NASA datasets: **M2TMNXSLV**, **M2TMNXRAD**, and **M2TMNXFLX**. All of these datasets are derived from NASA's research and are available through the NASA GES DISC (Global Earth Science Data and Information Service).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27663bd8-a827-4eb8-bdf1-25ba90179eed",
   "metadata": {},
   "source": [
    "### Library Imports and Authentication with NASA EarthData\n",
    "\n",
    "This block of code imports the necessary libraries and performs authentication with NASA EarthData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33a9f1e-69bd-40d2-a329-6fa7e11ffc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Earthdata Login username:  grazinha\n",
      "Enter your Earthdata password:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import psutil, time\n",
    "\n",
    "auth = earthaccess.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654a5fd-23c4-4a63-8efa-7ac1132a15b8",
   "metadata": {},
   "source": [
    "### Download Configuration\n",
    "\n",
    "This code block handles the configuration for downloading the dataset, specifically filtering the data for the area of Brazil, selecting specific variables, defining a specific time range, and setting the directory for the download. Additionally, a filtering step was applied to reduce the number of variables being downloaded, as well as selecting a specific time range and year to make the dataset lighter and more manageable for download on a typical machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79751e21-9175-4028-afa6-1287899f5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box do Brasil\n",
    "bbox = (-74.0, -33.74, -34.79, 5.27)\n",
    "\n",
    "# Vari√°veis\n",
    "vars_slv = [\"T2M\", \"QV2M\", \"PS\"]   # atmosf√©ricas\n",
    "vars_rad = [\"SWGDN\"]               # radia√ß√£o\n",
    "vars_precip = [\"PRECTOT\"]          # Precipita√ß√£o total\n",
    "\n",
    "# Per√≠odo\n",
    "start_year, end_year = 2007, 2025\n",
    "\n",
    "# Pasta de sa√≠da\n",
    "output_dir = Path(\"clima_brasil_mensal\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Lista para consolida√ß√£o final\n",
    "all_dfs = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499af625-039c-4b55-82aa-751e038a3a72",
   "metadata": {},
   "source": [
    "### Download Loop\n",
    "\n",
    "This code block is designed to execute the necessary downloads. A loop is created to download data from January 2007 to July 2025. For each year, it searches for the required variables in each dataset. We opted for the dataset version that provides monthly data instead of daily data for performance reasons. \n",
    "\n",
    "Error handling is implemented to account for any unavailable data, and a merge operation is performed across the three datasets to combine them into a single dataset with the requested variables. At the end of the process, the data is converted into a DataFrame and saved in Parquet format. \n",
    "\n",
    "For each year, the loop reports the time it took to download the data and the amount of memory used during the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb687290-a03c-4d72-bde6-8485b3a5cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop mensal j√° agregado\n",
    "for year in range(start_year, end_year + 1):\n",
    "    if year == 2025:\n",
    "        months = range(1, 8)  # at√© julho de 2025\n",
    "    else:\n",
    "        months = range(1, 13)\n",
    "\n",
    "    print(f\"\\nüì• Processando {year}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Buscar dados SLV (mensal)\n",
    "    results_slv = earthaccess.search_data(\n",
    "        short_name=\"M2TMNXSLV\",\n",
    "        version=\"5.12.4\",\n",
    "        temporal=(f\"{year}-01-01\", f\"{year}-12-31\"),\n",
    "        bounding_box=bbox\n",
    "    )\n",
    "\n",
    "    # Buscar dados RAD (mensal)\n",
    "    results_rad = earthaccess.search_data(\n",
    "        short_name=\"M2TMNXRAD\",\n",
    "        version=\"5.12.4\",\n",
    "        temporal=(f\"{year}-01-01\", f\"{year}-12-31\"),\n",
    "        bounding_box=bbox\n",
    "    )\n",
    "\n",
    "    # Buscar dados de precipita√ß√£o\n",
    "    results_precip = earthaccess.search_data(\n",
    "        short_name=\"M2TMNXFLX\",\n",
    "        version=\"5.12.4\",\n",
    "        temporal=(f\"{year}-01-01\", f\"{year}-12-31\"),\n",
    "        bounding_box=bbox\n",
    "    )\n",
    "\n",
    "    if not results_slv or not results_rad or not results_precip:\n",
    "        print(f\"‚ö†Ô∏è Nenhum dado encontrado para {year}\")\n",
    "        continue\n",
    "\n",
    "    # Abrir datasets j√° mensais\n",
    "    ds_slv = xr.open_mfdataset(\n",
    "        earthaccess.open(results_slv),\n",
    "        combine=\"by_coords\", chunks={\"time\": 1}\n",
    "    )[vars_slv]\n",
    "\n",
    "    ds_rad = xr.open_mfdataset(\n",
    "        earthaccess.open(results_rad),\n",
    "        combine=\"by_coords\", chunks={\"time\": 1}\n",
    "    )[vars_rad]\n",
    "\n",
    "    ds_precip = xr.open_mfdataset(\n",
    "        earthaccess.open(results_precip),\n",
    "        combine=\"by_coords\", chunks={\"time\": 1}\n",
    "    )[vars_precip]\n",
    "\n",
    "    # Merge direto (adicionando precipita√ß√£o)\n",
    "    ds = xr.merge([ds_slv, ds_rad, ds_precip])\n",
    "\n",
    "    # Converter em DataFrame\n",
    "    df = ds.to_dataframe().reset_index()\n",
    "\n",
    "    # Salvar parquet anual\n",
    "    out_path = output_dir / f\"clima_brasil_{year}.parquet\"\n",
    "    df.to_parquet(out_path, index=False)\n",
    "\n",
    "    all_dfs.append(df)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    mem = psutil.Process().memory_info().rss / (1024 ** 2)\n",
    "    print(f\"‚úÖ {year} salvo! Tempo: {elapsed:.1f}s | Mem√≥ria usada: {mem:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc5419-c369-4a10-9796-6e9c31e84c49",
   "metadata": {},
   "source": [
    "### Consolidating Data\n",
    "\n",
    "This code block consolidates all the downloaded data from each year into a single dataset. The previously collected DataFrames are concatenated into one final DataFrame using `pd.concat()`. The resulting dataset is then saved in two formats: Parquet and CSV. \n",
    "\n",
    "The Parquet file is saved for efficient storage and performance, while the CSV file is saved for easy readability and compatibility with other applications.\n",
    "\n",
    "At the end, a success message is printed to confirm that the dataset has been successfully consolidated and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dc013-c237-4c96-b61c-54f8e63721ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidar tudo\n",
    "df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "df_final.to_parquet(output_dir / \"clima_brasil_2000_2025.parquet\", index=False)\n",
    "df_final.to_csv(output_dir / \"clima_brasil_2000_2025.csv\", index=False)\n",
    "\n",
    "print(\"üéâ Dataset consolidado salvo com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
